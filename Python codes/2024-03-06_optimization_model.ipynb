{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to download all needed libraries - needs to be run every time\n",
    "\n",
    "from __future__ import division #used in Python2.x so the division btw integers result in float, default in python3\n",
    "from pyomo.environ import * #library for modeling and optimisation\n",
    "import argparse\n",
    "from pyomo.opt import SolverStatus, TerminationCondition #provide status of solvers\n",
    "import pandas as pd #data manipulation library\n",
    "import numpy as np \n",
    "import pickle\n",
    "import random\n",
    "import sqlite3\n",
    "import copy\n",
    "import random\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "INTEREST = 0.03 #interest rate\n",
    "\n",
    "scen = 500 #number of scenarios for stochastic optimization\n",
    "\n",
    "\n",
    "path = \"C:/VoI/\"  #specify the path to the working folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CODE GENERATED SCENARIOS AND CREATES NEW DATAFRAME WITH ASSIGNED SCENARIOS \n",
    "#ONLY RUN THIS WHEN GENERATIN SCENARIOS FOR THE FIRST TIME\n",
    "\n",
    "data_opt =  pd.read_csv(path+\"direct_10_22.csv\")  #Specify the input file\n",
    "id = set(data_opt.id)\n",
    "\n",
    "num_iterations = 6 #change according to number of the simulations for each stand in the input file\n",
    "\n",
    "for k in range(0,scen):\n",
    "    for i in list(id):\n",
    "        if i == list(id)[0]:\n",
    "            if k == 0:\n",
    "                data_scen = data_opt[(data_opt['id']==i) & (data_opt['iteration']==random.choice(range(1,num_iterations)))]\n",
    "                data_scen['SCENARIO'] = k\n",
    "            else:\n",
    "                data_scen_temp = data_opt[(data_opt['id']==i) & (data_opt['iteration']==random.choice(range(1,num_iterations)))]\n",
    "                data_scen_temp['SCENARIO'] = k\n",
    "                data_scen = pd.concat([data_scen,data_scen_temp])\n",
    "        else:\n",
    "            data_scen_temp = data_opt[(data_opt['id']==i) & (data_opt['iteration']==random.choice(range(1,num_iterations)))]\n",
    "            data_scen_temp['SCENARIO'] = k\n",
    "            data_scen = pd.concat([data_scen,data_scen_temp])\n",
    "\n",
    "data_scen\n",
    "\n",
    "data_scen.to_csv(path+\"Input/scenario_tables/data_scen_direct_10_22_500.csv\")  #Saves the new dataframe with scenarios, specify the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NONE\n",
      "NONE\n",
      "NONE\n",
      "NONE\n",
      "NONE\n",
      "NONE\n"
     ]
    }
   ],
   "source": [
    "#The code with the main model. Enough to run it once, after that shorter version could be used to change targets or other parameters\n",
    "\n",
    "#This part of the code creates the optimization model\n",
    "\n",
    "class optimization:\n",
    "    def __init__(self):\n",
    "        \n",
    "        data_opt =  pd.read_csv(path+\"Input/scenario_tables/data_scen_direct_10_22_500.csv\") #Specify the path to input file with all scenarios (generated in previous step)\n",
    "        all_data = data_opt\n",
    "        all_data = all_data.set_index(['id','branch','year','SCENARIO']) #reassigns the Df with new multi-level index\n",
    "        all_data = all_data.fillna(0) #fills any missing values with 0\n",
    "        all_data['year'] = all_data.index.get_level_values(2)\n",
    "        \n",
    "        self.data_opt=all_data #store the fetched or preprocessed data for use within the class\n",
    "        self.combinations = 1\n",
    "        self.all_data = self.data_opt\n",
    "        self.Index_values = self.all_data.drop(['year'], axis=1).reset_index().set_index(['id','branch']).index.unique() #we drop year, because we dont make decision for each year\n",
    "        self.area = self.all_data.loc[slice(None),0,1,self.all_data.index.get_level_values(3).min()]['area']\n",
    "        self.all_data = self.all_data.fillna(0)\n",
    "\n",
    "        self.createModel()\n",
    "\n",
    "    def createModel(self):\n",
    "        # Declare sets - These used to recongnize the number of stands, regimes and number of periods in the analysis.\n",
    "        # Define sets, variables, and constraints for the optimization problem\n",
    "        \n",
    "        self.model1 = ConcreteModel() #defining the model\n",
    "        \n",
    "        self.model1.stands = Set(initialize = list(set(self.all_data.index.get_level_values(0)))) #initialized with unique values from the first level of the index created earlier\n",
    "        self.model1.year = Set(initialize = list(set(self.all_data.index.get_level_values(2)))) #initialized with unique values from the third level of the index created earlier\n",
    "        self.model1.SCENARIO = Set(initialize = list(set(self.all_data.index.get_level_values(3))))        \n",
    "        self.model1.regimes = Set(initialize = list(set(self.all_data.index.get_level_values(1))))\n",
    "        self.model1.scen_index = Set(initialize= [i for i in range(0,self.combinations)])\n",
    "        self.model1.Index_values = self.Index_values\n",
    "\n",
    "        # Indexes (stand, regime)-- excludes those combinations that have no regimes simulated -- because some regimes are not simulated for some stands\n",
    "\n",
    "        def index_rule(model1):\n",
    "            index = []\n",
    "            for (s,r) in model1.Index_values: \n",
    "                index.append((s,r))\n",
    "            return index\n",
    "        self.model1.index1 = Set(dimen=2, initialize=index_rule)\n",
    "\n",
    "        #Decision variable\n",
    "        self.model1.X1 = Var(self.model1.index1, within=NonNegativeReals, bounds=(0,1), initialize=1)  \n",
    "\n",
    "        self.all_data['year'] = self.all_data.index.get_level_values(2)\n",
    "\n",
    "        #Objective and constraint don't need to be adjusted here, leave as it is, used to create the optimization model in the code. \n",
    "        #objective function:\n",
    "        def outcome_rule(model1):\n",
    "            return sum((self.all_data.Harvested_V.loc[(s,r,k,it)]*self.all_data.area.loc[(s,r,k,it)]* self.model1.X1[(s,r)])/((1+INTEREST)**(2.5+self.all_data.year[(s,r,k,it)]))  for (s,r) in self.model1.index1 for k in self.model1.year for it in self.model1.SCENARIO)\n",
    "        self.model1.OBJ = Objective(rule=outcome_rule, sense=maximize)\n",
    "\n",
    "        #Constraint:\n",
    "        def regime_rule(model1, s):\n",
    "            row_sum = sum(model1.X1[(s,r)] for r in [x[1] for x in model1.index1 if x[0] == s])\n",
    "            return row_sum == 1\n",
    "        self.model1.regime_limit = Constraint(self.model1.stands, rule=regime_rule)\n",
    "\n",
    "    def solve(self):\n",
    "        # Specify the solver and solve the model\n",
    "        opt = SolverFactory('cplex') #Here we use CPLEX solver, could be adjusted to use open-sources ones (for example, cbc)\n",
    "        self.results = opt.solve(self.model1,tee=False) #We solve a problem, but do not show the solver output\n",
    "\n",
    "# Create an optimization object        \n",
    "t1 = optimization()\n",
    "t2 = copy.deepcopy(t1)\n",
    "\n",
    "# Modify the optimization model to focus on. \n",
    "\n",
    "try:\n",
    "    t2.model1.del_component(t2.model1.NPV_INV)\n",
    "except:\n",
    "    print(\"NONE\")\n",
    "\n",
    "#A function that evaluates NPV (already discounted in Gaya simulated output)  \n",
    "t2.model1.NPV= Var(within=NonNegativeReals) \n",
    "def NPV_INVENTORY(model1):\n",
    "    row_sum = sum(t2.all_data.NPV.loc[(s,r,10,it)]*t2.all_data.area.loc[(s,r,10,it)]* t2.model1.X1[(s,r)]  for (s,r) in t2.model1.index1 for it in t2.model1.SCENARIO)/scen\n",
    "    return t2.model1.NPV ==row_sum\n",
    "t2.model1.NPV_INV= Constraint(rule=NPV_INVENTORY)  \n",
    "\n",
    "#A function that evaluates the combined HSI per stand\n",
    "\n",
    "t2.all_data['CHSI'] = 1- ((1-t2.all_data.LSWP)*(1-t2.all_data.TTWP)*(1-t2.all_data.LTT)*(1-t2.all_data.CAP)*(1-t2.all_data.HAZ))\n",
    "\n",
    "try:\n",
    "    t2.model1.del_component(t2.model1.COMB_HSI)\n",
    "except:\n",
    "    print(\"NONE\")\n",
    "\n",
    "try:\n",
    "    t2.model1.del_component(t2.model1.LAND_HSI)\n",
    "except:\n",
    "    print(\"NONE\")\n",
    "\n",
    "try:\n",
    "    t2.model1.del_component(t2.model1.HSI)\n",
    "except:\n",
    "    print(\"NONE\")\n",
    "\n",
    "try:\n",
    "    t2.model1.del_component(t2.model1.Landscape_HSI)\n",
    "except:\n",
    "    print(\"NONE\")\n",
    "\n",
    "t2.model1.HSI=Var(t2.model1.stands, t2.model1.year, within=NonNegativeReals)\n",
    "def COMBINED_HSI(model1, s, k):\n",
    "    birds = (sum(t2.model1.X1[(s,r)] * t2.all_data.CHSI.loc[(s,r,k,it)] for r in [x[1] for x in t2.model1.index1 if x[0] == s] for it in t2.model1.SCENARIO)) / scen\n",
    "    return t2.model1.HSI[(s,k)] == birds\n",
    "t2.model1.COMB_HSI = Constraint(t2.model1.stands,t2.model1.year, rule=COMBINED_HSI)\n",
    "\n",
    "#A function that evaluates the combined HSI for the landscape\n",
    "t2.model1.Landscape_HSI=Var(t2.model1.year, within=NonNegativeReals)\n",
    "def Landscape_HSI(model1, k):\n",
    "    Land_HSI = sum(t2.model1.HSI[(s,k)]*t2.area[s] for s in t2.model1.stands)\n",
    "    return t2.model1.Landscape_HSI[k] == Land_HSI\n",
    "t2.model1.LAND_HSI = Constraint(t2.model1.year, rule=Landscape_HSI)\n",
    "\n",
    "#A function that computes the total value as sum per periods\n",
    "t2.model1.Landscape_HSI_Tot = Var(within=NonNegativeReals)\n",
    "def HSI_Tot(model1):\n",
    "    row_sum = sum(t2.model1.Landscape_HSI[k] for k in t2.model1.year)\n",
    "    return t2.model1.Landscape_HSI_Tot == row_sum\n",
    "t2.model1.LAND_HSI_TOTAL = Constraint(rule=HSI_Tot)\n",
    "\n",
    "#code for computing CVaR\n",
    "\n",
    "#Downside CVaR\n",
    "t2.model1.CVAR_down = Var(t2.model1.year,within=Reals, initialize=1)\n",
    "t2.model1.VAR_down = Var(t2.model1.year,within=Reals, initialize=1)\n",
    "t2.model1.posVAR_down = Var(t2.model1.year,t2.model1.SCENARIO, within=NonNegativeReals, initialize=1)\n",
    "t2.model1.negVAR_down = Var(t2.model1.year,t2.model1.SCENARIO, within=NonNegativeReals, initialize=1)\n",
    "t2.model1.mod_L_plus_down = Var(t2.model1.year,t2.model1.SCENARIO, within=NonNegativeReals, initialize=1)\n",
    "t2.model1.mod_L_neg_down = Var(t2.model1.year,t2.model1.SCENARIO, within=NonNegativeReals, initialize=1)\n",
    "t2.model1.alpha_risk_down = Param(default=0.80, mutable=True) #Specify here the confidence interval\n",
    "t2.model1.target_down = Param(default=600000, mutable=True) #Specify here the desired minimum periodic income\n",
    "t2.model1.CVAR_down_Tot = Var(within=Reals)\n",
    "\n",
    "\n",
    "#Equations to computre downside CVaR\n",
    "def CVAR_constraint_down(model1,k):\n",
    "    CVAR_down = t2.model1.VAR_down[k] + (1/((1-t2.model1.alpha_risk_down)*scen))*sum(t2.model1.posVAR_down[k,scenario] for scenario in t2.model1.SCENARIO)\n",
    "    return t2.model1.CVAR_down[k] == CVAR_down\n",
    "t2.model1.CVAR_constraint_down = Constraint(t2.model1.year,rule=CVAR_constraint_down)\n",
    "\n",
    "def MOD_L_P_constraint_down(model1,k,it):\n",
    "    VAL_down = t2.model1.mod_L_plus_down[k,it] -t2.model1.VAR_down[k]+t2.model1.negVAR_down[k,it]-t2.model1.posVAR_down[k,it]\n",
    "    return VAL_down == 0\n",
    "t2.model1.MOD_L_P_down = Constraint(t2.model1.year,t2.model1.SCENARIO,rule=MOD_L_P_constraint_down)\n",
    "\n",
    "def MOD_TARGET_constraint_down(model1,k,it):\n",
    "    row_sum = sum(((t2.all_data.INC.loc[(s,r,k,it)])*t2.all_data.area.loc[(s,r,k,it)]* t2.model1.X1[(s,r)]) for (s,r) in t2.model1.index1)\n",
    "    VAL = t2.model1.target_down-row_sum - t2.model1.mod_L_plus_down[k,it]+t2.model1.mod_L_neg_down[k,it]\n",
    "    return VAL == 0\n",
    "t2.model1.MOD_Target_down = Constraint(t2.model1.year,t2.model1.SCENARIO,rule=MOD_TARGET_constraint_down)\n",
    "\n",
    "def CVAR_down_constraint(model1):\n",
    "    row_sum = sum(t2.model1.CVAR_down[k] for k in t2.model1.year)\n",
    "    return t2.model1.CVAR_down_Tot == row_sum \n",
    "t2.model1.CVAR_tot_down = Constraint(rule=CVAR_down_constraint)\n",
    "\n",
    "\n",
    "#Upside CVaR\n",
    "t2.model1.CVAR_up = Var(t2.model1.year,within=Reals, initialize=1)\n",
    "t2.model1.VAR_up = Var(t2.model1.year,within=Reals, initialize=1)\n",
    "t2.model1.posVAR_up = Var(t2.model1.year,t2.model1.SCENARIO, within=NonNegativeReals, initialize=1)\n",
    "t2.model1.negVAR_up = Var(t2.model1.year,t2.model1.SCENARIO, within=NonNegativeReals, initialize=1)\n",
    "t2.model1.mod_L_plus_up = Var(t2.model1.year,t2.model1.SCENARIO, within=NonNegativeReals, initialize=1)\n",
    "t2.model1.mod_L_neg_up = Var(t2.model1.year,t2.model1.SCENARIO, within=NonNegativeReals, initialize=1)\n",
    "t2.model1.alpha_risk_up = Param(default=0.80, mutable=True) #Specify here the confidence interval\n",
    "t2.model1.target_up = Param(default=800000, mutable=True) #Specify here the desired maximum periodic income\n",
    "t2.model1.CVAR_up_Tot = Var(within=Reals)\n",
    "\n",
    "#Equations to computre upside CVaR\n",
    "def CVAR_constraint_up(model1,k):\n",
    "    CVAR_up = t2.model1.VAR_up[k] + (1/((1-t2.model1.alpha_risk_up)*scen))*sum(t2.model1.negVAR_up[k,scenario] for scenario in t2.model1.SCENARIO)\n",
    "    return t2.model1.CVAR_up[k] == CVAR_up\n",
    "t2.model1.CVAR_constraint_up = Constraint(t2.model1.year,rule=CVAR_constraint_up)\n",
    "\n",
    "def MOD_L_P_constraint_up(model1,k,it):\n",
    "    VAL_up = t2.model1.mod_L_neg_up[k,it] -t2.model1.VAR_up[k]-t2.model1.negVAR_up[k,it]+t2.model1.posVAR_up[k,it]\n",
    "    return VAL_up == 0\n",
    "t2.model1.MOD_L_P_up = Constraint(t2.model1.year,t2.model1.SCENARIO,rule=MOD_L_P_constraint_up)\n",
    "\n",
    "def MOD_TARGET_constraint_up(model1,k,it):\n",
    "    row_sum = sum(((t2.all_data.INC.loc[(s,r,k,it)])*t2.all_data.area.loc[(s,r,k,it)]* t2.model1.X1[(s,r)]) for (s,r) in t2.model1.index1)\n",
    "    VAL = t2.model1.target_up - row_sum - t2.model1.mod_L_plus_up[k,it]+t2.model1.mod_L_neg_up[k,it]\n",
    "    return VAL == 0\n",
    "t2.model1.MOD_Target_up = Constraint(t2.model1.year,t2.model1.SCENARIO,rule=MOD_TARGET_constraint_up)\n",
    "\n",
    "def CVAR_up_constraint(model1):\n",
    "    row_sum = sum(t2.model1.CVAR_up[k] for k in t2.model1.year)\n",
    "    return t2.model1.CVAR_up_Tot == row_sum \n",
    "t2.model1.CVAR_tot_up = Constraint(rule=CVAR_up_constraint)\n",
    "\n",
    "#Equations to compute standing end volume \n",
    "\n",
    "t2.model1.EndVolume = Var(within=NonNegativeReals)\n",
    "def End_volume_constraint(model1):\n",
    "    row_sum = sum(t2.all_data.V_end.loc[(s,r,10,it)]*t2.all_data.area.loc[(s,r,10,it)]* t2.model1.X1[(s,r)]  for (s,r) in t2.model1.index1 for it in t2.model1.SCENARIO)/scen\n",
    "    return t2.model1.EndVolume == row_sum\n",
    "t2.model1.EndInv = Constraint(rule=End_volume_constraint)\n",
    "\n",
    "#minimum and maximum values and target parameters. If knowm - adjust here, if unknown yet - will be computed later\n",
    "\n",
    "t2.model1.NPV_min = Param(default=93064.4153858999, mutable=True)\n",
    "t2.model1.NPV_max = Param(default=1412635.71273736, mutable=True)\n",
    "t2.model1.NPV_target = Param(default=1500000, mutable=True)\n",
    "\n",
    "t2.model1.HSI_min = Param(default=163.953968012528, mutable=True)\n",
    "t2.model1.HSI_max = Param(default=239.51424384946, mutable=True)\n",
    "t2.model1.HSI_target = Param(default=400, mutable=True)\n",
    "\n",
    "t2.model1.CVAR_down_min = Param(default=126344.885279602, mutable=True)\n",
    "t2.model1.CVAR_down_max = Param(default=6061218.19076652, mutable=True)\n",
    "t2.model1.CVAR_down_target = Param(default=0, mutable=True)\n",
    "\n",
    "t2.model1.CVAR_up_min = Param(default=0.00, mutable=True)\n",
    "t2.model1.CVAR_up_max = Param(default=5324657.29371336, mutable=True)\n",
    "t2.model1.CVAR_up_target = Param(default=0, mutable=True)\n",
    "\n",
    "t2.model1.EndVol_min = Param(default=11110.158276522, mutable=True)\n",
    "t2.model1.EndVol_max = Param(default=26633.5645745358, mutable=True)\n",
    "t2.model1.EndVol_target = Param(default=0, mutable=True)\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    t2.model1.del_component(t2.model1.OBJ)\n",
    "except:\n",
    "    print(\"NONE\")\n",
    "\n",
    "#Objective function -- currently minimizing the downside CVaR   \n",
    "def outcome_rule(model1):\n",
    "    return - t2.model1.CVAR_down_Tot \n",
    "t2.model1.OBJ = Objective(rule=outcome_rule, sense=maximize)\n",
    "\n",
    "# Solve the modified optimization model\n",
    "t2.solve()\n",
    "\n",
    "#Function to extract decision variables from the optimized model\n",
    "def GET_DECISION_DATA():\n",
    "        st = []\n",
    "        reg = []\n",
    "        vals = []\n",
    "        for (s,r) in t2.model1.index1:\n",
    "            st = st+[s]\n",
    "            reg = reg+[r] \n",
    "            vals = vals+[t2.model1.X1[(s,r)].value]\n",
    "        data = {\"id\":st,\"branch\":reg,\"value\":vals}\n",
    "        df= pd.DataFrame(data)\n",
    "        df = df.set_index(['id','branch'])\n",
    "        return df\n",
    "\n",
    "# Extract decision data and merge with original dataset    \n",
    "dec  = GET_DECISION_DATA()\n",
    "merged_df = dec.merge(t2.all_data, left_index=True, right_index=True, how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code creates a payoff table - can be used after the previous code is executed\n",
    "\n",
    "\n",
    "def RE_TRY(t2,VAL):\n",
    "    t2.model1.del_component(t2.model1.OBJ)\n",
    "    def outcome_rule1(model1):\n",
    "        if VAL == \"NPV\":\n",
    "            return t2.model1.NPV  - t2.model1.CVAR_down_Tot*0.00001 - t2.model1.CVAR_up_Tot*0.00001  #CVaR is included to ensure its proper calculation. Multiplied by a small number to ensure it does not influence the optimal solution \n",
    "        elif VAL == \"END\":\n",
    "            return t2.model1.EndVolume - t2.model1.CVAR_down_Tot*0.00001 - t2.model1.CVAR_up_Tot*0.00001\n",
    "        elif VAL == \"CVAR_up\":\n",
    "            return - t2.model1.CVAR_up_Tot - t2.model1.CVAR_down_Tot*0.0000001\n",
    "        elif VAL == \"CVAR_down\":\n",
    "            return - t2.model1.CVAR_down_Tot - t2.model1.CVAR_up_Tot*0.0000001\n",
    "        elif VAL == \"HSI\":\n",
    "            return t2.model1.Landscape_HSI_Tot - t2.model1.CVAR_down_Tot*0.000001 - t2.model1.CVAR_up_Tot*0.000001\n",
    "    t2.model1.OBJ = Objective(rule=outcome_rule1, sense=maximize)\n",
    "    # Solve the modified optimization model\n",
    "    t2.solve()\n",
    "    t2a ={\"NPV\":t2.model1.NPV.value,\"EndVolume\": t2.model1.EndVolume.value,\"CVAR_up_Tot\": t2.model1.CVAR_up_Tot.value,\"CVAR_down_Tot\": t2.model1.CVAR_down_Tot.value,\"Landscape_HSI_Tot\": t2.model1.Landscape_HSI_Tot.value}\n",
    "    return t2a\n",
    "t2a = RE_TRY(t2,\"NPV\")\n",
    "t2b = RE_TRY(t2,\"END\")\n",
    "t2c = RE_TRY(t2,\"CVAR_up\")\n",
    "t2d = RE_TRY(t2,\"CVAR_down\")\n",
    "t2e = RE_TRY(t2,\"HSI\")\n",
    " \n",
    "\n",
    "data = [t2a, t2b,t2c,t2d,t2e]\n",
    " \n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "(df.T).to_csv(path+\"Outputs/Payoff_tables/payoff_direct.csv\")  #Define the path to save the payoff table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4281021.491273181 2517359.7537621805\n",
      "33395.8714681528 3952.862299524629\n",
      "4158671.894452451 0.0\n",
      "5974176.839872 0.0\n",
      "216.89822420154042 74.13831636700425\n"
     ]
    }
   ],
   "source": [
    "#This code will extract the minimum and maximum values from the payoff table\n",
    "\n",
    "import csv\n",
    "\n",
    "def get_max_and_min_values_in_row(csv_file, row_number):\n",
    "    with open(csv_file, newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "        # Skip the header row\n",
    "        next(reader)\n",
    "        for _ in range(row_number - 1):\n",
    "            try:\n",
    "                row = next(reader)\n",
    "            except StopIteration:\n",
    "                return None, None, None, None\n",
    "        \n",
    "        variable_name = row[0].strip()  \n",
    "        values = []\n",
    "        for value in row[1:]:\n",
    "            try:\n",
    "                numeric_value = float(value)\n",
    "                values.append(numeric_value)\n",
    "            except ValueError:\n",
    "                pass  \n",
    "        if values:\n",
    "            max_value = max(values)\n",
    "            min_value = min(values)\n",
    "        else:\n",
    "            max_value = None\n",
    "            min_value = None\n",
    "        return variable_name + \"_Max\", max_value, variable_name + \"_Min\", min_value\n",
    "\n",
    "#The path to payoff table\n",
    "csv_file = path+\"Outputs/Payoff_tables/payoff_direct.csv\"\n",
    "\n",
    "for row_number in range(2, 7):  # Identify the rown with values, skipping the header\n",
    "    max_var_name, max_value, min_var_name, min_value = get_max_and_min_values_in_row(csv_file, row_number)\n",
    "    if max_var_name is not None:\n",
    "        locals()[max_var_name] = max_value\n",
    "    if min_var_name is not None:\n",
    "        locals()[min_var_name] = min_value\n",
    "\n",
    "\n",
    "#Store the extracted minimum and maximum values as parameters for the optimization model\n",
    "t2.model1.NPV_min = NPV_Min\n",
    "t2.model1.NPV_max = NPV_Max\n",
    "\n",
    "t2.model1.HSI_min = Landscape_HSI_Tot_Min\n",
    "t2.model1.HSI_max = Landscape_HSI_Tot_Max\n",
    "\n",
    "t2.model1.CVAR_down_min = CVAR_down_Tot_Min\n",
    "t2.model1.CVAR_down_max = CVAR_down_Tot_Max\n",
    "\n",
    "t2.model1.CVAR_up_min = CVAR_up_Tot_Min\n",
    "t2.model1.CVAR_up_max = CVAR_up_Tot_Max\n",
    "\n",
    "t2.model1.EndVol_min = EndVolume_Min\n",
    "t2.model1.EndVol_max = EndVolume_Max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Implicitly replacing the Component attribute D (type=<class\n",
      "'pyomo.core.base.var.ScalarVar'>) on block unknown with a new Component\n",
      "(type=<class 'pyomo.core.base.var.AbstractScalarVar'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute NPV_D (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute END_V_D (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute HSI_D (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute CVAR_down_D (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute CVAR_up_D (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute OBJ (type=<class\n",
      "'pyomo.core.base.objective.ScalarObjective'>) on block unknown with a new\n",
      "Component (type=<class 'pyomo.core.base.objective.ScalarObjective'>). This is\n",
      "usually indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n"
     ]
    }
   ],
   "source": [
    "#This code defines the achievement-scalarizing objective function and runs the model for final outputs \n",
    "\n",
    "t2.model1.D = Var(within=Reals)\n",
    "\n",
    "def NPV_D_constraint(model1):\n",
    "    row_sum = ((t2.model1.NPV - t2.model1.NPV_target)/(t2.model1.NPV_max-t2.model1.NPV_min))\n",
    "    return t2.model1.D <= row_sum \n",
    "t2.model1.NPV_D = Constraint(rule=NPV_D_constraint)\n",
    " \n",
    "def End_V_D_constraint(model1):\n",
    "    row_sum = ((t2.model1.EndVolume - t2.model1.EndVol_target)/(t2.model1.EndVol_max - t2.model1.EndVol_min))\n",
    "    return t2.model1.D <= row_sum \n",
    "t2.model1.END_V_D = Constraint(rule=End_V_D_constraint)\n",
    " \n",
    "def HSI_D_constraint(model1):\n",
    "    row_sum = ((t2.model1.Landscape_HSI_Tot - t2.model1.HSI_target)/(t2.model1.HSI_max - t2.model1.HSI_min))\n",
    "    return t2.model1.D <= row_sum \n",
    "t2.model1.HSI_D = Constraint(rule=HSI_D_constraint)\n",
    "\n",
    "def CVAR_down_D_constraint(model1):\n",
    "    row_sum = ((t2.model1.CVAR_down_target-t2.model1.CVAR_down_Tot)/(t2.model1.CVAR_down_max - t2.model1.CVAR_down_min))\n",
    "    return t2.model1.D <= row_sum \n",
    "t2.model1.CVAR_down_D = Constraint(rule=CVAR_down_D_constraint)\n",
    "\n",
    "def CVAR_up_D_constraint(model1):\n",
    "    row_sum = ((t2.model1.CVAR_up_target-t2.model1.CVAR_up_Tot)/(t2.model1.CVAR_up_max - t2.model1.CVAR_up_min))\n",
    "    return t2.model1.D <= row_sum \n",
    "t2.model1.CVAR_up_D = Constraint(rule=CVAR_up_D_constraint)\n",
    " \n",
    "#Decision-maker's targets defined here\n",
    "t2.model1.NPV_target = 3500000\n",
    "t2.model1.CVAR_down_target = 5500000\n",
    "t2.model1.CVAR_up_target = 3500000\n",
    "t2.model1.HSI_target = 190\n",
    "t2.model1.EndVol_target = 26000\n",
    " \n",
    "#Objective function    \n",
    "\n",
    "def outcome_rule(model1):\n",
    "    return ((t2.model1.D + 0.001*(((t2.model1.NPV)/(t2.model1.NPV_max-t2.model1.NPV_min)) + \n",
    "            ((t2.model1.EndVolume)/(t2.model1.EndVol_max - t2.model1.EndVol_min)) + \n",
    "            ((t2.model1.Landscape_HSI_Tot)/(t2.model1.HSI_max - t2.model1.HSI_min)) -\n",
    "            ((t2.model1.CVAR_down_Tot)/(t2.model1.CVAR_down_max - t2.model1.CVAR_down_min)) -\n",
    "            ((t2.model1.CVAR_up_Tot)/(t2.model1.CVAR_up_max - t2.model1.CVAR_up_min))\n",
    "            ) )*10000)\n",
    "t2.model1.OBJ = Objective(rule=outcome_rule, sense=maximize)\n",
    "\n",
    "\n",
    "t2.solve()\n",
    "\n",
    "#Function to extract decision variables from the optimized model\n",
    "def GET_DECISION_DATA():\n",
    "        st = []\n",
    "        reg = []\n",
    "        vals = []\n",
    "        for (s,r) in t2.model1.index1:\n",
    "            st = st+[s]\n",
    "            reg = reg+[r] \n",
    "            vals = vals+[t2.model1.X1[(s,r)].value]\n",
    "        data = {\"id\":st,\"branch\":reg,\"value\":vals}\n",
    "        df= pd.DataFrame(data)\n",
    "        df = df.set_index(['id','branch'])\n",
    "        return df\n",
    "\n",
    "# Extract decision data and merge with original dataset    \n",
    "dec  = GET_DECISION_DATA()\n",
    "merged_df = dec.merge(t2.all_data, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Save results to a CSV file\n",
    "merged_df.to_csv(path+\"Outputs/direct_target1.csv\")  #Specify the path to save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPV:\n",
      "2620801.1669585253\n",
      "CVaR_down:\n",
      "28517464.812615003\n",
      "CVaR_up:\n",
      "0.0\n",
      "Landscape HSI total:\n",
      "216.89822420154047\n",
      "Expected end inventory volume\n",
      "32588.119057917083\n"
     ]
    }
   ],
   "source": [
    "#Print values for main criteria\n",
    "\n",
    "print(\"NPV:\")\n",
    "print(t2.model1.NPV.value)\n",
    "\n",
    "print(\"CVaR_down:\")\n",
    "print(t2.model1.CVAR_down_Tot.value)\n",
    "\n",
    "print(\"CVaR_up:\")\n",
    "print(t2.model1.CVAR_up_Tot.value)\n",
    "\n",
    "print(\"Landscape HSI total:\")\n",
    "print(t2.model1.Landscape_HSI_Tot.value)\n",
    "\n",
    "print(\"Expected end inventory volume\")\n",
    "print(t2.model1.EndVolume.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.042518728856289226\n",
      "0.1382971029794552\n",
      "0.5161621802973769\n",
      "-0.042518728856289094\n",
      "-0.0425187288562892\n"
     ]
    }
   ],
   "source": [
    "#Compute the distances to the targets\n",
    "\n",
    "print((t2.model1.NPV.value - t2.model1.NPV_target.value)/(t2.model1.NPV_max.value-t2.model1.NPV_min.value)) \n",
    "print((t2.model1.CVAR_down_target.value - t2.model1.CVAR_down_Tot.value)/(t2.model1.CVAR_down_max.value - t2.model1.CVAR_down_min.value))\n",
    "print((t2.model1.CVAR_up_target.value -t2.model1.CVAR_up_Tot.value)/(t2.model1.CVAR_up_max.value - t2.model1.CVAR_up_min.value)) \n",
    "print((t2.model1.Landscape_HSI_Tot.value - t2.model1.HSI_target.value)/(t2.model1.HSI_max.value - t2.model1.HSI_min.value)) \n",
    "print((t2.model1.EndVolume.value - t2.model1.EndVol_target.value)/(t2.model1.EndVol_max.value - t2.model1.EndVol_min.value))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYOMO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}  
